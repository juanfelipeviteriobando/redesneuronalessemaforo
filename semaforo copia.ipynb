{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cv2\n",
    "\n",
    "def iniciarCamara():\n",
    "    print(\"iniciando modulo\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        print(\"No se pudo abrir la cámara\")\n",
    "        return\n",
    "    print(\"Camara Abierta\")\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error al encontrar imagen\")\n",
    "            break\n",
    "        cv2.imshow(\"camara 1\", frame)  # <- aquí estaba el error\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Esc para salir\n",
    "            break\n",
    "        rojo = frame[:,:,1]\n",
    "        cv2.imshow(\"Capa Roja\",rojo)\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Este bloque previene que se ejecute dos veces si lo importas en otro script\n",
    "if __name__ == \"__main__\":\n",
    "    iniciarCamara()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "red MLP",
   "id": "619c41519dc9f475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#red mlp",
   "id": "6b3b3a9ce2c813d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T02:37:34.364365Z",
     "start_time": "2025-06-01T02:36:57.347366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# entrenamiento.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import psutil  # Para uso de recursos (CPU y Memoria)\n",
    "\n",
    "# Definir el modelo MLP\n",
    "def crear_modelo():\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(64, input_dim=3, activation='relu'))  # 3 características (promedio de R, G, B)\n",
    "    modelo.add(Dense(32, activation='relu'))\n",
    "    modelo.add(Dense(3, activation='softmax'))  # 3 clases: rojo, amarillo, verde\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "# Generar datos de entrenamiento\n",
    "def generar_datos(n=1000):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        R = np.random.randint(0, 256)\n",
    "        G = np.random.randint(0, 256)\n",
    "        B = np.random.randint(0, 256)\n",
    "\n",
    "        X_train.append([R, G, B])\n",
    "\n",
    "        if R > G and R > B:\n",
    "            y_train.append(0)  # Rojo\n",
    "        elif G > R and G > B:\n",
    "            y_train.append(1)  # Amarillo\n",
    "        else:\n",
    "            y_train.append(2)  # Verde\n",
    "\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Función para evaluar precisión y tasa de error en los datos de prueba\n",
    "def evaluar_precision(modelo, X_test, y_test):\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    y_pred = np.argmax(predicciones, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    correctas = np.sum(y_pred == y_true)\n",
    "    total = len(y_true)\n",
    "    precision = correctas / total\n",
    "    tasa_error = 1 - precision\n",
    "\n",
    "    return precision, tasa_error\n",
    "\n",
    "# Entrenar la red neuronal con los datos generados\n",
    "def entrenar_red():\n",
    "    # Generar conjunto de datos\n",
    "    X_train, y_train = generar_datos(10000)  # 10,000 ejemplos\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    y_train_onehot = tf.keras.utils.to_categorical(y_train_encoded, 3)\n",
    "\n",
    "    # Dividir datos en entrenamiento y validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear modelo\n",
    "    modelo = crear_modelo()\n",
    "\n",
    "    # Medir tiempo de entrenamiento\n",
    "    start_time = time.time()\n",
    "    modelo.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Tiempo de entrenamiento\n",
    "    tiempo_entrenamiento = end_time - start_time\n",
    "    print(f\"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos\")\n",
    "\n",
    "    # Evaluar precisión y tasa de error en datos de validación\n",
    "    precision, tasa_error = evaluar_precision(modelo, X_val, y_val)\n",
    "    print(f\"Precisión en datos de validación: {precision * 100:.2f}%\")\n",
    "    print(f\"Tasa de error en datos de validación: {tasa_error * 100:.2f}%\")\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    modelo.save(\"modelo_semaforo.h5\")\n",
    "    print(\"Modelo guardado como 'modelo_semaforo.h5'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    entrenar_red()\n"
   ],
   "id": "5ff74d6690162d86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\PycharmProjects\\JupyterProject\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.7853 - loss: 4.6267 - val_accuracy: 0.9600 - val_loss: 0.1144\n",
      "Epoch 2/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9696 - loss: 0.1014 - val_accuracy: 0.9400 - val_loss: 0.1829\n",
      "Epoch 3/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9781 - loss: 0.0829 - val_accuracy: 0.9745 - val_loss: 0.0553\n",
      "Epoch 4/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9704 - loss: 0.0844 - val_accuracy: 0.9435 - val_loss: 0.1664\n",
      "Epoch 5/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9829 - loss: 0.0483 - val_accuracy: 0.9835 - val_loss: 0.0482\n",
      "Epoch 6/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9727 - loss: 0.0856 - val_accuracy: 0.9885 - val_loss: 0.0294\n",
      "Epoch 7/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9795 - loss: 0.0566 - val_accuracy: 0.9835 - val_loss: 0.0364\n",
      "Epoch 8/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9771 - loss: 0.0584 - val_accuracy: 0.9610 - val_loss: 0.1340\n",
      "Epoch 9/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9751 - loss: 0.0728 - val_accuracy: 0.9730 - val_loss: 0.1058\n",
      "Epoch 10/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9707 - loss: 0.0964 - val_accuracy: 0.9520 - val_loss: 0.1887\n",
      "Epoch 11/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9743 - loss: 0.0782 - val_accuracy: 0.9835 - val_loss: 0.0487\n",
      "Epoch 12/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9712 - loss: 0.1325 - val_accuracy: 0.9790 - val_loss: 0.0464\n",
      "Epoch 13/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9826 - loss: 0.0494 - val_accuracy: 0.9875 - val_loss: 0.0342\n",
      "Epoch 14/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9826 - loss: 0.0442 - val_accuracy: 0.9855 - val_loss: 0.0354\n",
      "Epoch 15/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9874 - loss: 0.0369 - val_accuracy: 0.9810 - val_loss: 0.0526\n",
      "Epoch 16/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9844 - loss: 0.0467 - val_accuracy: 0.9840 - val_loss: 0.0366\n",
      "Epoch 17/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9765 - loss: 0.0842 - val_accuracy: 0.9680 - val_loss: 0.0812\n",
      "Epoch 18/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9750 - loss: 0.0764 - val_accuracy: 0.9660 - val_loss: 0.1067\n",
      "Epoch 19/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9836 - loss: 0.0430 - val_accuracy: 0.9880 - val_loss: 0.0274\n",
      "Epoch 20/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9839 - loss: 0.0447 - val_accuracy: 0.9735 - val_loss: 0.1030\n",
      "Epoch 21/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9834 - loss: 0.0476 - val_accuracy: 0.9845 - val_loss: 0.0411\n",
      "Epoch 22/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9820 - loss: 0.0558 - val_accuracy: 0.9920 - val_loss: 0.0236\n",
      "Epoch 23/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9880 - loss: 0.0310 - val_accuracy: 0.9900 - val_loss: 0.0293\n",
      "Epoch 24/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9866 - loss: 0.0316 - val_accuracy: 0.9880 - val_loss: 0.0304\n",
      "Epoch 25/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9839 - loss: 0.0446 - val_accuracy: 0.9720 - val_loss: 0.0895\n",
      "Epoch 26/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9802 - loss: 0.0742 - val_accuracy: 0.9865 - val_loss: 0.0311\n",
      "Epoch 27/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9851 - loss: 0.0438 - val_accuracy: 0.9900 - val_loss: 0.0278\n",
      "Epoch 28/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9854 - loss: 0.0381 - val_accuracy: 0.9765 - val_loss: 0.0747\n",
      "Epoch 29/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9864 - loss: 0.0339 - val_accuracy: 0.9820 - val_loss: 0.0481\n",
      "Epoch 30/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9841 - loss: 0.0414 - val_accuracy: 0.9815 - val_loss: 0.0428\n",
      "Epoch 31/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9847 - loss: 0.0401 - val_accuracy: 0.9915 - val_loss: 0.0252\n",
      "Epoch 32/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9850 - loss: 0.0538 - val_accuracy: 0.9870 - val_loss: 0.0288\n",
      "Epoch 33/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9871 - loss: 0.0389 - val_accuracy: 0.9940 - val_loss: 0.0196\n",
      "Epoch 34/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9874 - loss: 0.0372 - val_accuracy: 0.9930 - val_loss: 0.0208\n",
      "Epoch 35/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9874 - loss: 0.0365 - val_accuracy: 0.9900 - val_loss: 0.0272\n",
      "Epoch 36/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9872 - loss: 0.0376 - val_accuracy: 0.9770 - val_loss: 0.0582\n",
      "Epoch 37/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9873 - loss: 0.0306 - val_accuracy: 0.9915 - val_loss: 0.0236\n",
      "Epoch 38/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9889 - loss: 0.0296 - val_accuracy: 0.9800 - val_loss: 0.0564\n",
      "Epoch 39/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9791 - loss: 0.0766 - val_accuracy: 0.9835 - val_loss: 0.0371\n",
      "Epoch 40/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9894 - loss: 0.0300 - val_accuracy: 0.9940 - val_loss: 0.0189\n",
      "Epoch 41/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9859 - loss: 0.0375 - val_accuracy: 0.9925 - val_loss: 0.0241\n",
      "Epoch 42/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9863 - loss: 0.0520 - val_accuracy: 0.9875 - val_loss: 0.0286\n",
      "Epoch 43/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9788 - loss: 0.0592 - val_accuracy: 0.9905 - val_loss: 0.0251\n",
      "Epoch 44/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9850 - loss: 0.0412 - val_accuracy: 0.9870 - val_loss: 0.0321\n",
      "Epoch 45/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9901 - loss: 0.0305 - val_accuracy: 0.9885 - val_loss: 0.0271\n",
      "Epoch 46/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9891 - loss: 0.0325 - val_accuracy: 0.9875 - val_loss: 0.0324\n",
      "Epoch 47/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9825 - loss: 0.0548 - val_accuracy: 0.9880 - val_loss: 0.0304\n",
      "Epoch 48/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9850 - loss: 0.0371 - val_accuracy: 0.9860 - val_loss: 0.0314\n",
      "Epoch 49/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9858 - loss: 0.0404 - val_accuracy: 0.9760 - val_loss: 0.0702\n",
      "Epoch 50/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9853 - loss: 0.0361 - val_accuracy: 0.9855 - val_loss: 0.0362\n",
      "Tiempo de entrenamiento: 30.77 segundos\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step  \n",
      "Precisión en datos de validación: 98.55%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tasa de error en datos de validación: 1.45%\n",
      "Modelo guardado como 'modelo_semaforo.h5'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T03:07:28.523108600Z",
     "start_time": "2025-06-01T03:07:13.951641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prediccion.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import psutil  # Para uso de recursos (CPU y Memoria)\n",
    "\n",
    "# Cargar el modelo previamente entrenado\n",
    "modelo = tf.keras.models.load_model(\"modelo_semaforo.h5\")\n",
    "\n",
    "# Preprocesar la imagen para extraer los colores predominantes\n",
    "def obtener_color_promedio(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    rango_rojo = ((0, 100, 100), (10, 255, 255))\n",
    "    rango_amarillo = ((20, 100, 100), (40, 255, 255))\n",
    "    rango_verde = ((40, 100, 100), (80, 255, 255))\n",
    "\n",
    "    rojo = cv2.inRange(hsv, rango_rojo[0], rango_rojo[1])\n",
    "    amarillo = cv2.inRange(hsv, rango_amarillo[0], rango_amarillo[1])\n",
    "    verde = cv2.inRange(hsv, rango_verde[0], rango_verde[1])\n",
    "\n",
    "    promedio_rojo = cv2.countNonZero(rojo)\n",
    "    promedio_amarillo = cv2.countNonZero(amarillo)\n",
    "    promedio_verde = cv2.countNonZero(verde)\n",
    "\n",
    "    return np.array([promedio_rojo, promedio_amarillo, promedio_verde])\n",
    "\n",
    "# Función para predecir el color del semáforo en tiempo real\n",
    "def predecir_color(frame):\n",
    "    promedio_colores = obtener_color_promedio(frame)\n",
    "    start_time = time.time()\n",
    "    prediccion = modelo.predict(np.array([promedio_colores]), verbose=0)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Medir tiempo de ejecución\n",
    "    tiempo_ejecucion = (end_time - start_time) * 1000  # en milisegundos\n",
    "\n",
    "    clase_predicha = np.argmax(prediccion)\n",
    "\n",
    "    if clase_predicha == 0:\n",
    "        color_predicho = \"Semaforo: Rojo - Detengase\"\n",
    "    elif clase_predicha == 1:\n",
    "        color_predicho = \"Semaforo: Amarillo - Precaucion\"\n",
    "    elif clase_predicha == 2:\n",
    "        color_predicho = \"Semaforo: Verde - Puede avanzar\"\n",
    "\n",
    "    return color_predicho, tiempo_ejecucion\n",
    "\n",
    "# Iniciar la cámara y usar el modelo para predecir el color del semáforo\n",
    "def iniciarCamara():\n",
    "    print(\"Iniciando módulo de cámara...\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cam.isOpened():\n",
    "        print(\"No se pudo abrir la cámara\")\n",
    "        return\n",
    "\n",
    "    print(\"Cámara abierta\")\n",
    "\n",
    "    predicciones_correctas = 0\n",
    "    total_predicciones = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error al capturar imagen\")\n",
    "            break\n",
    "\n",
    "        color_predicho, tiempo_ejecucion = predecir_color(frame)\n",
    "\n",
    "        # Actualizar estadísticas\n",
    "        total_predicciones += 1\n",
    "        if color_predicho == \"Semaforo: Rojo - Detengase\":  # Suponiendo que sea el color correcto\n",
    "            predicciones_correctas += 1\n",
    "\n",
    "        precision = predicciones_correctas / total_predicciones\n",
    "        print(f\"Precisión: {precision * 100:.2f}%\")\n",
    "        print(f\"Tiempo de ejecución (frame): {tiempo_ejecucion:.2f} ms\")\n",
    "\n",
    "        # Mostrar información en la pantalla\n",
    "        cv2.putText(frame, f\"Color: {color_predicho}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Tiempo: {tiempo_ejecucion:.2f} ms\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Camara\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciarCamara()\n"
   ],
   "id": "26ee0e1e1f822ea1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando módulo de cámara...\n",
      "Cámara abierta\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 137.69 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 75.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 78.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 92.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 70.99 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.06 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 83.02 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 199.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 78.48 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 86.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 83.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.04 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 78.92 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 75.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 91.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 72.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 82.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 76.02 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 87.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.03 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 72.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 78.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.03 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.13 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 83.15 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.81 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 82.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 83.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.02 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 75.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.99 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.43 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 71.03 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.02 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 72.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.97 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 101.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.99 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 75.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 83.51 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 71.43 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.99 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 72.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 71.53 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 82.03 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 71.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 74.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 86.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 86.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.99 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 76.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 77.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 80.03 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 72.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.41 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 94.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 81.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 78.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 99.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 98.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 75.00 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 79.01 ms\n",
      "Precisión: 0.00%\n",
      "Tiempo de ejecución (frame): 73.04 ms\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#red de hopfield",
   "id": "d275451a698144c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#red de hopfield",
   "id": "680c3bba64bf8110"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T03:10:47.767780Z",
     "start_time": "2025-06-01T03:10:47.614734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#red de hopfield\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Función de activación para la red Hopfield\n",
    "def activacion(patron):\n",
    "    return np.where(patron >= 0, 1, -1)\n",
    "\n",
    "\n",
    "# Red Hopfield\n",
    "class RedHopfield:\n",
    "    def __init__(self, tamaño):\n",
    "        self.tamaño = tamaño\n",
    "        self.pesos = np.zeros((tamaño, tamaño))\n",
    "\n",
    "    def entrenar(self, patrones):\n",
    "        print(\"Entrenando la red Hopfield...\")\n",
    "        for idx, patron in enumerate(patrones):\n",
    "            patron = patron.reshape(-1, 1)\n",
    "            self.pesos += np.dot(patron, patron.T)\n",
    "            np.fill_diagonal(self.pesos, 0)  # Las neuronas no se conectan entre sí\n",
    "            print(f\"\\nPesos después de entrenar el patrón {idx + 1} ({['Rojo', 'Amarillo', 'Verde'][idx]}):\")\n",
    "            print(self.pesos)\n",
    "\n",
    "    def reconocer(self, entrada):\n",
    "        entrada = entrada.reshape(-1, 1)\n",
    "        salida = np.copy(entrada)\n",
    "        iteracion = 0\n",
    "        while True:\n",
    "            iteracion += 1\n",
    "            salida_anterior = salida.copy()\n",
    "            salida = activacion(np.dot(self.pesos, salida))\n",
    "\n",
    "            # Imprimir los pesos y la salida en cada iteración\n",
    "            print(f\"\\nIteración {iteracion} de reconocimiento:\")\n",
    "            print(\"Pesos actuales:\")\n",
    "            print(self.pesos)\n",
    "            print(\"Salida actual:\")\n",
    "            print(salida.flatten())\n",
    "\n",
    "            if np.array_equal(salida, salida_anterior):\n",
    "                break\n",
    "        return salida.flatten()\n",
    "\n",
    "\n",
    "# Crear los patrones para los colores del semáforo\n",
    "rojo = np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])  # Color Rojo\n",
    "amarillo = np.array([-1, 1, -1, 1, -1, 1, -1, 1, -1])  # Color Amarillo\n",
    "verde = np.array([-1, -1, 1, -1, -1, 1, 1, -1, -1])  # Color Verde\n",
    "\n",
    "# Entrenamiento\n",
    "patrones = [rojo, amarillo, verde]\n",
    "red = RedHopfield(tamaño=9)\n",
    "red.entrenar(patrones)\n",
    "\n",
    "# Guardar los pesos entrenados\n",
    "np.save('pesos_hopfield.npy', red.pesos)\n",
    "print(\"\\nEntrenamiento completado. Pesos guardados como 'pesos_hopfield.npy'.\\n\")\n",
    "\n",
    "# Ejemplo de reconocimiento\n",
    "entrada = np.array([-1, -1, -1, -1, 1, 1, -1, -1, -1])  # Ejemplo de entrada para \"rojo\"\n",
    "print(\"Reconociendo la entrada:\")\n",
    "reconocimiento = red.reconocer(entrada)\n",
    "print(f\"\\nPatrón reconocido: {reconocimiento}\")\n"
   ],
   "id": "a29cb597793fa67e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando la red Hopfield...\n",
      "\n",
      "Pesos después de entrenar el patrón 1 (Rojo):\n",
      "[[ 0. -1. -1. -1.  1. -1. -1. -1.  1.]\n",
      " [-1.  0.  1.  1. -1.  1.  1.  1. -1.]\n",
      " [-1.  1.  0.  1. -1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1.  0. -1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1.  0. -1. -1. -1.  1.]\n",
      " [-1.  1.  1.  1. -1.  0.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.  1.  0. -1.]\n",
      " [ 1. -1. -1. -1.  1. -1. -1. -1.  0.]]\n",
      "\n",
      "Pesos después de entrenar el patrón 2 (Amarillo):\n",
      "[[ 0. -2.  0. -2.  2. -2.  0. -2.  2.]\n",
      " [-2.  0.  0.  2. -2.  2.  0.  2. -2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  2.  0.  0.]\n",
      " [-2.  2.  0.  0. -2.  2.  0.  2. -2.]\n",
      " [ 2. -2.  0. -2.  0. -2.  0. -2.  2.]\n",
      " [-2.  2.  0.  2. -2.  0.  0.  2. -2.]\n",
      " [ 0.  0.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [-2.  2.  0.  2. -2.  2.  0.  0. -2.]\n",
      " [ 2. -2.  0. -2.  2. -2.  0. -2.  0.]]\n",
      "\n",
      "Pesos después de entrenar el patrón 3 (Verde):\n",
      "[[ 0. -1. -1. -1.  3. -3. -1. -1.  3.]\n",
      " [-1.  0. -1.  3. -1.  1. -1.  3. -1.]\n",
      " [-1. -1.  0. -1. -1.  1.  3. -1. -1.]\n",
      " [-1.  3. -1.  0. -1.  1. -1.  3. -1.]\n",
      " [ 3. -1. -1. -1.  0. -3. -1. -1.  3.]\n",
      " [-3.  1.  1.  1. -3.  0.  1.  1. -3.]\n",
      " [-1. -1.  3. -1. -1.  1.  0. -1. -1.]\n",
      " [-1.  3. -1.  3. -1.  1. -1.  0. -1.]\n",
      " [ 3. -1. -1. -1.  3. -3. -1. -1.  0.]]\n",
      "\n",
      "Entrenamiento completado. Pesos guardados como 'pesos_hopfield.npy'.\n",
      "\n",
      "Reconociendo la entrada:\n",
      "\n",
      "Iteración 1 de reconocimiento:\n",
      "Pesos actuales:\n",
      "[[ 0. -1. -1. -1.  3. -3. -1. -1.  3.]\n",
      " [-1.  0. -1.  3. -1.  1. -1.  3. -1.]\n",
      " [-1. -1.  0. -1. -1.  1.  3. -1. -1.]\n",
      " [-1.  3. -1.  0. -1.  1. -1.  3. -1.]\n",
      " [ 3. -1. -1. -1.  0. -3. -1. -1.  3.]\n",
      " [-3.  1.  1.  1. -3.  0.  1.  1. -3.]\n",
      " [-1. -1.  3. -1. -1.  1.  0. -1. -1.]\n",
      " [-1.  3. -1.  3. -1.  1. -1.  0. -1.]\n",
      " [ 3. -1. -1. -1.  3. -3. -1. -1.  0.]]\n",
      "Salida actual:\n",
      "[ 1 -1  1 -1 -1 -1  1 -1  1]\n",
      "\n",
      "Iteración 2 de reconocimiento:\n",
      "Pesos actuales:\n",
      "[[ 0. -1. -1. -1.  3. -3. -1. -1.  3.]\n",
      " [-1.  0. -1.  3. -1.  1. -1.  3. -1.]\n",
      " [-1. -1.  0. -1. -1.  1.  3. -1. -1.]\n",
      " [-1.  3. -1.  0. -1.  1. -1.  3. -1.]\n",
      " [ 3. -1. -1. -1.  0. -3. -1. -1.  3.]\n",
      " [-3.  1.  1.  1. -3.  0.  1.  1. -3.]\n",
      " [-1. -1.  3. -1. -1.  1.  0. -1. -1.]\n",
      " [-1.  3. -1.  3. -1.  1. -1.  0. -1.]\n",
      " [ 3. -1. -1. -1.  3. -3. -1. -1.  0.]]\n",
      "Salida actual:\n",
      "[ 1 -1  1 -1  1 -1  1 -1  1]\n",
      "\n",
      "Iteración 3 de reconocimiento:\n",
      "Pesos actuales:\n",
      "[[ 0. -1. -1. -1.  3. -3. -1. -1.  3.]\n",
      " [-1.  0. -1.  3. -1.  1. -1.  3. -1.]\n",
      " [-1. -1.  0. -1. -1.  1.  3. -1. -1.]\n",
      " [-1.  3. -1.  0. -1.  1. -1.  3. -1.]\n",
      " [ 3. -1. -1. -1.  0. -3. -1. -1.  3.]\n",
      " [-3.  1.  1.  1. -3.  0.  1.  1. -3.]\n",
      " [-1. -1.  3. -1. -1.  1.  0. -1. -1.]\n",
      " [-1.  3. -1.  3. -1.  1. -1.  0. -1.]\n",
      " [ 3. -1. -1. -1.  3. -3. -1. -1.  0.]]\n",
      "Salida actual:\n",
      "[ 1 -1  1 -1  1 -1  1 -1  1]\n",
      "\n",
      "Patrón reconocido: [ 1 -1  1 -1  1 -1  1 -1  1]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T03:11:30.799490Z",
     "start_time": "2025-06-01T03:10:54.247248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Función de activación para la red Hopfield\n",
    "def activacion(patron):\n",
    "    return np.where(patron >= 0, 1, -1)\n",
    "\n",
    "\n",
    "# Red Hopfield\n",
    "class RedHopfield:\n",
    "    def __init__(self, tamaño, pesos):\n",
    "        self.tamaño = tamaño\n",
    "        self.pesos = pesos\n",
    "\n",
    "    def reconocer(self, entrada):\n",
    "        entrada = entrada.reshape(-1, 1)\n",
    "        salida = np.copy(entrada)\n",
    "        while True:\n",
    "            salida_anterior = salida.copy()\n",
    "            salida = activacion(np.dot(self.pesos, salida))\n",
    "            if np.array_equal(salida, salida_anterior):\n",
    "                break\n",
    "        return salida.flatten()\n",
    "\n",
    "\n",
    "# Función para identificar el color basado en la entrada\n",
    "def identificar_color(frame):\n",
    "    # Convertir la imagen a espacio de color HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Definir los rangos de color para rojo, amarillo y verde\n",
    "    # Rojo\n",
    "    rojo_bajo = np.array([0, 120, 70])\n",
    "    rojo_alto = np.array([10, 255, 255])\n",
    "    rojo_mask = cv2.inRange(hsv, rojo_bajo, rojo_alto)\n",
    "\n",
    "    # Amarillo\n",
    "    amarillo_bajo = np.array([20, 100, 100])\n",
    "    amarillo_alto = np.array([40, 255, 255])\n",
    "    amarillo_mask = cv2.inRange(hsv, amarillo_bajo, amarillo_alto)\n",
    "\n",
    "    # Verde\n",
    "    verde_bajo = np.array([35, 50, 50])\n",
    "    verde_alto = np.array([85, 255, 255])\n",
    "    verde_mask = cv2.inRange(hsv, verde_bajo, verde_alto)\n",
    "\n",
    "    # Contar los píxeles de cada color\n",
    "    rojo_cont = np.sum(rojo_mask)\n",
    "    amarillo_cont = np.sum(amarillo_mask)\n",
    "    verde_cont = np.sum(verde_mask)\n",
    "\n",
    "    # Decidir el color predominante\n",
    "    if rojo_cont > max(amarillo_cont, verde_cont):\n",
    "        return np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])  # Rojo\n",
    "    elif verde_cont > max(rojo_cont, amarillo_cont):\n",
    "        return np.array([-1, -1, 1, -1, -1, 1, 1, -1, -1])  # Verde\n",
    "    else:\n",
    "        return np.array([-1, 1, -1, 1, -1, 1, -1, 1, -1])  # Amarillo\n",
    "\n",
    "\n",
    "def iniciarCamara():\n",
    "    print(\"Iniciando módulo\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        print(\"No se pudo abrir la cámara\")\n",
    "        return\n",
    "    print(\"Cámara abierta\")\n",
    "\n",
    "    # Cargar los pesos entrenados\n",
    "    try:\n",
    "        pesos_hopfield = np.load('pesos_hopfield.npy')\n",
    "        print(\"Pesos de la red Hopfield cargados correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los pesos entrenados: {e}\")\n",
    "        return\n",
    "\n",
    "    # Crear la red Hopfield con los pesos cargados\n",
    "    red = RedHopfield(tamaño=9, pesos=pesos_hopfield)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error al encontrar imagen\")\n",
    "            break\n",
    "\n",
    "        # Extraer color y predecir usando la red Hopfield\n",
    "        entrada = identificar_color(frame)\n",
    "        color_identificado = red.reconocer(entrada)\n",
    "\n",
    "        # Determinar el color predicho\n",
    "        if np.array_equal(color_identificado, np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])):  # Rojo\n",
    "            texto = \"Semáforo: Rojo - Deténgase\"\n",
    "        elif np.array_equal(color_identificado, np.array([-1, -1, 1, -1, -1, 1, 1, -1, -1])):  # Verde\n",
    "            texto = \"Semáforo: Verde - Puede avanzar\"\n",
    "        else:  # Amarillo\n",
    "            texto = \"Semáforo: Amarillo - Precaución\"\n",
    "\n",
    "        # Mostrar el texto en la imagen de la cámara\n",
    "        cv2.putText(frame, texto, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Mostrar el frame con el texto\n",
    "        cv2.imshow(\"Cámara\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Escape para salir\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Ejecutar la cámara\n",
    "if __name__ == \"__main__\":\n",
    "    iniciarCamara()"
   ],
   "id": "6298b5384021fa0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando módulo\n",
      "Cámara abierta\n",
      "Pesos de la red Hopfield cargados correctamente.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#codigo de datos cuantitativos",
   "id": "dfb0def96cc1d531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T03:12:30.316985Z",
     "start_time": "2025-06-01T03:11:43.372288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Función de activación para la red Hopfield\n",
    "def activacion(patron):\n",
    "    return np.where(patron >= 0, 1, -1)\n",
    "\n",
    "# Red Hopfield\n",
    "class RedHopfield:\n",
    "    def __init__(self, tamaño, pesos):\n",
    "        self.tamaño = tamaño\n",
    "        self.pesos = pesos\n",
    "\n",
    "    def reconocer(self, entrada):\n",
    "        entrada = entrada.reshape(-1, 1)\n",
    "        salida = np.copy(entrada)\n",
    "        while True:\n",
    "            salida_anterior = salida.copy()\n",
    "            salida = activacion(np.dot(self.pesos, salida))\n",
    "            if np.array_equal(salida, salida_anterior):\n",
    "                break\n",
    "        return salida.flatten()\n",
    "\n",
    "# Función para identificar el color basado en la entrada\n",
    "def identificar_color(frame):\n",
    "    # Convertir la imagen a espacio de color HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Definir los rangos de color para rojo, amarillo y verde\n",
    "    rojo_bajo = np.array([0, 120, 70])\n",
    "    rojo_alto = np.array([10, 255, 255])\n",
    "    rojo_mask = cv2.inRange(hsv, rojo_bajo, rojo_alto)\n",
    "\n",
    "    amarillo_bajo = np.array([20, 100, 100])\n",
    "    amarillo_alto = np.array([40, 255, 255])\n",
    "    amarillo_mask = cv2.inRange(hsv, amarillo_bajo, amarillo_alto)\n",
    "\n",
    "    verde_bajo = np.array([35, 50, 50])\n",
    "    verde_alto = np.array([85, 255, 255])\n",
    "    verde_mask = cv2.inRange(hsv, verde_bajo, verde_alto)\n",
    "\n",
    "    rojo_cont = np.sum(rojo_mask)\n",
    "    amarillo_cont = np.sum(amarillo_mask)\n",
    "    verde_cont = np.sum(verde_mask)\n",
    "\n",
    "    if rojo_cont > max(amarillo_cont, verde_cont):\n",
    "        return np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])  # Rojo\n",
    "    elif verde_cont > max(rojo_cont, amarillo_cont):\n",
    "        return np.array([-1, -1, 1, -1, -1, 1, 1, -1, -1])  # Verde\n",
    "    else:\n",
    "        return np.array([-1, 1, -1, 1, -1, 1, -1, 1, -1])  # Amarillo\n",
    "\n",
    "def iniciarCamara(color_objetivo='rojo'):\n",
    "    print(\"Iniciando módulo\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        print(\"No se pudo abrir la cámara\")\n",
    "        return\n",
    "    print(\"Cámara abierta\")\n",
    "\n",
    "    # Cargar los pesos entrenados\n",
    "    try:\n",
    "        pesos_hopfield = np.load('pesos_hopfield.npy')\n",
    "        print(\"Pesos de la red Hopfield cargados correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los pesos entrenados: {e}\")\n",
    "        return\n",
    "\n",
    "    # Crear la red Hopfield con los pesos cargados\n",
    "    red = RedHopfield(tamaño=9, pesos=pesos_hopfield)\n",
    "\n",
    "    # Criterios Cuantitativos\n",
    "    predicciones_correctas = 0\n",
    "    total_predicciones = 0\n",
    "    errores = 0\n",
    "    tiempos = []\n",
    "\n",
    "    # Para el uso de recursos\n",
    "    proceso = psutil.Process()\n",
    "\n",
    "    # Define el color objetivo para medir precisión (rojo, amarillo o verde)\n",
    "    if color_objetivo == 'rojo':\n",
    "        color_real = np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])  # Color Rojo\n",
    "    elif color_objetivo == 'amarillo':\n",
    "        color_real = np.array([-1, 1, -1, 1, -1, 1, -1, 1, -1])  # Color Amarillo\n",
    "    elif color_objetivo == 'verde':\n",
    "        color_real = np.array([-1, -1, 1, -1, -1, 1, 1, -1, -1])  # Color Verde\n",
    "    else:\n",
    "        print(f\"Color no válido: {color_objetivo}. Usando rojo por defecto.\")\n",
    "        color_real = np.array([1, -1, -1, -1, 1, -1, -1, -1, 1])  # Color Rojo\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error al encontrar imagen\")\n",
    "            break\n",
    "\n",
    "        # Extraer color y predecir usando la red Hopfield\n",
    "        entrada = identificar_color(frame)\n",
    "        start_time = time.time()\n",
    "\n",
    "        color_identificado = red.reconocer(entrada)\n",
    "\n",
    "        # Medir el tiempo de ejecución\n",
    "        end_time = time.time()\n",
    "        tiempos.append(end_time - start_time)\n",
    "\n",
    "        # Determinar el color predicho y el valor real\n",
    "        if np.array_equal(color_identificado, color_real):\n",
    "            texto = f\"Semáforo: {color_objetivo.capitalize()} - Predicción Correcta\"\n",
    "            predicciones_correctas += 1\n",
    "        else:\n",
    "            texto = f\"Semáforo: {color_objetivo.capitalize()} - Predicción Incorrecta\"\n",
    "            errores += 1\n",
    "\n",
    "        # Actualizar el contador de predicciones\n",
    "        total_predicciones += 1\n",
    "\n",
    "        # Mostrar el texto en la imagen de la cámara\n",
    "        cv2.putText(frame, texto, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Mostrar el frame con el texto\n",
    "        cv2.imshow(\"Cámara\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Escape para salir\n",
    "            break\n",
    "\n",
    "    # Calcular precisión y otros criterios\n",
    "    precision = predicciones_correctas / total_predicciones\n",
    "    latencia_media = np.mean(tiempos) * 1000  # en milisegundos\n",
    "    uso_cpu = proceso.cpu_percent(interval=1)\n",
    "    uso_memoria = proceso.memory_info().rss / 1024 / 1024  # en MB\n",
    "\n",
    "    print(f\"\\nCriterios Cuantitativos para el color {color_objetivo.capitalize()}:\")\n",
    "    print(f\"Precisión: {precision * 100:.2f}%\")\n",
    "    print(f\"Latencia Media: {latencia_media:.2f} ms\")\n",
    "    print(f\"Uso de CPU: {uso_cpu:.2f}%\")\n",
    "    print(f\"Uso de Memoria: {uso_memoria:.2f} MB\")\n",
    "    print(f\"Tasa de Error: {errores / total_predicciones * 100:.2f}%\")\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejecutar la cámara, evaluando el color rojo\n",
    "if __name__ == \"__main__\":\n",
    "    iniciarCamara(color_objetivo='rojo')  # Puedes cambiar 'rojo' por 'amarillo' o 'verde'\n"
   ],
   "id": "cd6d30efc1c14838",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando módulo\n",
      "Cámara abierta\n",
      "Pesos de la red Hopfield cargados correctamente.\n",
      "\n",
      "Criterios Cuantitativos para el color Rojo:\n",
      "Precisión: 43.64%\n",
      "Latencia Media: 0.05 ms\n",
      "Uso de CPU: 0.00%\n",
      "Uso de Memoria: 116.12 MB\n",
      "Tasa de Error: 56.36%\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#red de base radial",
   "id": "ab5e327b929d68ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T01:56:59.645232Z",
     "start_time": "2025-06-01T01:56:57.373232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Datos sintéticos: colores bien diferenciados\n",
    "X = np.array([\n",
    "    # ROJO (alto R, bajo G, bajo B)\n",
    "    [255, 0, 0],\n",
    "    [220, 20, 20],\n",
    "    [200, 10, 10],\n",
    "    [240, 30, 30],\n",
    "    [210, 15, 5],\n",
    "    [230, 0, 20],\n",
    "    [255, 50, 50],\n",
    "    [245, 40, 30],\n",
    "    [225, 25, 0],\n",
    "    [235, 10, 5],\n",
    "\n",
    "    # AMARILLO (alto R, alto G, bajo B)\n",
    "    [255, 255, 0],           # amarillo puro\n",
    "    [250, 250, 20],          # amarillo con más verde\n",
    "    [240, 240, 40],          # más verde que rojo\n",
    "    [255, 230, 20],          # más verde que rojo\n",
    "    [245, 245, 10],          # amarillo más suave\n",
    "    [255, 220, 10],          # más verde en amarillo\n",
    "    [230, 230, 30],          # amarillo más saturado\n",
    "    [255, 240, 10],          # más amarillo cálido\n",
    "    [250, 225, 20],          # amarillo oscuro\n",
    "    [255, 255, 50],          # amarillo con más verde\n",
    "\n",
    "    # VERDE (bajo R, alto G, bajo B)\n",
    "    [0, 255, 0],             # verde puro\n",
    "    [20, 240, 20],           # verde más oscuro\n",
    "    [30, 220, 30],           # verde con un toque de rojo\n",
    "    [10, 230, 10],           # verde muy claro\n",
    "    [0, 200, 0],             # verde más oscuro\n",
    "    [5, 210, 5],             # verde más suave\n",
    "    [25, 255, 25],           # verde claro\n",
    "    [15, 235, 15],           # verde cálido\n",
    "    [0, 180, 0],             # verde profundo\n",
    "    [10, 255, 30],           # verde brillante\n",
    "])\n",
    "\n",
    "# Etiquetas: 0=rojo, 1=amarillo, 2=verde\n",
    "y = np.array(\n",
    "    [0]*10 +  # rojo\n",
    "    [1]*10 +  # amarillo\n",
    "    [2]*10    # verde\n",
    ")\n",
    "\n",
    "# Clustering para obtener los centros RBF\n",
    "n_centros = 8  # Aumentar el número de centros para mejorar la clasificación\n",
    "kmeans = KMeans(n_clusters=n_centros, random_state=42).fit(X)\n",
    "centros = kmeans.cluster_centers_\n",
    "\n",
    "def rbf(x, centro, sigma=100.0):\n",
    "    return np.exp(-np.linalg.norm(x - centro)**2 / (2 * sigma**2))\n",
    "\n",
    "def transformar_con_rbf(X):\n",
    "    return np.array([[rbf(x, c) for c in centros] for x in X])\n",
    "\n",
    "# Transformar los datos con la capa RBF\n",
    "X_rbf = transformar_con_rbf(X)\n",
    "\n",
    "# Clasificador\n",
    "modelo = LogisticRegression(max_iter=100000)\n",
    "modelo.fit(X_rbf, y)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(modelo, 'modelo_rbf.pkl')\n",
    "joblib.dump(centros, 'centros_rbf.pkl')\n",
    "\n",
    "print(\"✅ Modelo RBF entrenado con colores más diferenciados.\")\n"
   ],
   "id": "67179ea5b0213f6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo RBF entrenado con colores más diferenciados.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T01:58:02.244641600Z",
     "start_time": "2025-06-01T01:57:52.457082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "modelo = joblib.load('modelo_rbf.pkl')\n",
    "centros = joblib.load('centros_rbf.pkl')\n",
    "\n",
    "def rbf(x, centro, sigma=100.0):\n",
    "    return np.exp(-np.linalg.norm(x - centro)**2 / (2 * sigma**2))\n",
    "\n",
    "def transformar_con_rbf(X):\n",
    "    return np.array([[rbf(x, c) for c in centros] for x in X])\n",
    "\n",
    "def detectar_color(frame):\n",
    "    # Redimensionar para acelerar\n",
    "    img = cv2.resize(frame, (100, 100))\n",
    "    # Calcular color promedio\n",
    "    promedio = img.mean(axis=0).mean(axis=0)  # BGR\n",
    "    promedio_rgb = promedio[::-1]  # Convertir a RGB\n",
    "    X_test = transformar_con_rbf([promedio_rgb])\n",
    "    pred = modelo.predict(X_test)[0]\n",
    "    return pred\n",
    "\n",
    "def advertir_color(color_id):\n",
    "    if color_id == 0:\n",
    "        return \"DETECTADO: ROJO - DETENER\"\n",
    "    elif color_id == 1:\n",
    "        return \"DETECTADO: AMARILLO - PRECAUCIÓN\"\n",
    "    elif color_id == 2:\n",
    "        return \"DETECTADO: VERDE - AVANZAR\"\n",
    "    return \"Color no identificado\"\n",
    "\n",
    "def iniciarCamara():\n",
    "    print(\"🔧 Iniciando cámara...\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        print(\"❌ No se pudo abrir la cámara\")\n",
    "        return\n",
    "    print(\"✅ Cámara abierta\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Error al capturar imagen\")\n",
    "            break\n",
    "\n",
    "        color_id = detectar_color(frame)\n",
    "        mensaje = advertir_color(color_id)\n",
    "        #print(mensaje)\n",
    "\n",
    "        # Mostrar cámara y mensaje\n",
    "        cv2.putText(frame, mensaje, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        cv2.imshow(\"Camara Semaforo RBF\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC para salir\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciarCamara()\n"
   ],
   "id": "a520ff12abbfb374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Iniciando cámara...\n",
      "✅ Cámara abierta\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#redes mapas autoorganizados",
   "id": "4c8c5592f86bcd44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#red de mapa autorganizados",
   "id": "9b940e50ad0d5f62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T01:53:52.577260Z",
     "start_time": "2025-06-01T01:53:52.206262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_som.py\n",
    "import numpy as np\n",
    "from minisom import MiniSom\n",
    "import pickle\n",
    "\n",
    "def generate_color_samples(center_rgb, spread=20, n_samples=500):\n",
    "    samples = np.clip(\n",
    "        np.random.randint(center_rgb - spread, center_rgb + spread + 1,\n",
    "                          size=(n_samples, 3)),\n",
    "        0, 255\n",
    "    )\n",
    "    return samples\n",
    "\n",
    "def main():\n",
    "    centers = {\n",
    "        'ROJO':    np.array([255,   0,   0]),\n",
    "        'AMARILLO':np.array([255, 255,   0]),\n",
    "        'VERDE':   np.array([  0, 255,   0]),\n",
    "    }\n",
    "\n",
    "    # Generar muestras y normalizar\n",
    "    data = []\n",
    "    for c in centers.values():\n",
    "        data.append(generate_color_samples(c))\n",
    "    data = np.vstack(data) / 255.0\n",
    "\n",
    "    # SOM de 3x1 con sigma mayor para mejor separación\n",
    "    som = MiniSom(3, 1, 3, sigma=1.0, learning_rate=0.5)\n",
    "    som.random_weights_init(data)\n",
    "    print(\"Entrenando SOM (5 000 iters)...\")\n",
    "    som.train_random(data, num_iteration=5000)\n",
    "    print(\"Entrenamiento completado.\")\n",
    "\n",
    "    # Mapeo neurona → etiqueta\n",
    "    mapping = {}\n",
    "    for label, center in centers.items():\n",
    "        win = som.winner(center / 255.0)\n",
    "        mapping[win] = label\n",
    "\n",
    "    with open('som_traffic_light.pkl', 'wb') as f:\n",
    "        pickle.dump({'som': som, 'mapping': mapping}, f)\n",
    "    print(\"Modelo guardado en 'som_traffic_light.pkl'.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "da229dee03ffd4ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando SOM (5 000 iters)...\n",
      "Entrenamiento completado.\n",
      "Modelo guardado en 'som_traffic_light.pkl'.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T02:03:41.534033300Z",
     "start_time": "2025-06-01T02:03:34.188550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_traffic_light_som.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "def load_model(path='som_traffic_light.pkl'):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['som'], data['mapping']\n",
    "\n",
    "def main():\n",
    "    som, mapping = load_model()\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        print(\"No se pudo abrir la cámara\")\n",
    "        return\n",
    "\n",
    "    print(\"Cámara iniciada. Presiona ESC para salir.\")\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error capturando frame\")\n",
    "            break\n",
    "\n",
    "        # 1) Convertir frame a RGB normalizado\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) / 255.0\n",
    "        h, w, _ = rgb.shape\n",
    "\n",
    "        # 2) Muestrear aleatoriamente 5000 píxeles\n",
    "        coords = np.random.randint(0, h*w, size=5000)\n",
    "        pixels = rgb.reshape(-1, 3)[coords]\n",
    "\n",
    "        # 3) Para cada píxel, obtener la neurona ganadora\n",
    "        wins = [som.winner(p) for p in pixels]\n",
    "        labels = [mapping.get(w, 'DESCONOCIDO') for w in wins]\n",
    "\n",
    "        # 4) Contar y elegir la etiqueta más frecuente\n",
    "        most_common = Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "        # 5) Dibujar resultado en el frame\n",
    "        color_text = {'ROJO':(0,0,255), 'AMARILLO':(0,255,255), 'VERDE':(0,255,0)}.get(most_common, (255,255,255))\n",
    "        cv2.putText(frame, f'Luz: {most_common}',\n",
    "                    (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, color_text, 2)\n",
    "\n",
    "        cv2.imshow(\"Detección Semáforo\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "7f39b6ccb8c90bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cámara iniciada. Presiona ESC para salir.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#red de ejecucion general",
   "id": "70d693b984febd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T02:08:05.650491Z",
     "start_time": "2025-06-01T02:07:58.141096Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "398b36b5ff106fbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleccione una opción:\n",
      "1. MLP (Perceptrón Multicapa)\n",
      "2. RBF (Radial Basis Function)\n",
      "3. Regresión Logística\n",
      "4. SOM (Self-Organizing Map)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but LogisticRegression is expecting 8 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 156\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;66;03m# Función para iniciar el programa\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[43miniciarCamara\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 120\u001B[0m, in \u001B[0;36miniciarCamara\u001B[1;34m()\u001B[0m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError al capturar imagen\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 120\u001B[0m color \u001B[38;5;241m=\u001B[39m \u001B[43mdetectar_color_rbf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodelo_logistic\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Cambiar si es necesario\u001B[39;00m\n\u001B[0;32m    121\u001B[0m cv2\u001B[38;5;241m.\u001B[39mputText(frame, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColor: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m50\u001B[39m), cv2\u001B[38;5;241m.\u001B[39mFONT_HERSHEY_SIMPLEX, \u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    122\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCamara\u001B[39m\u001B[38;5;124m\"\u001B[39m, frame)\n",
      "Cell \u001B[1;32mIn[2], line 45\u001B[0m, in \u001B[0;36mdetectar_color_rbf\u001B[1;34m(frame, modelo_rbf)\u001B[0m\n\u001B[0;32m     43\u001B[0m promedio_rgb \u001B[38;5;241m=\u001B[39m promedio[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# BGR a RGB\u001B[39;00m\n\u001B[0;32m     44\u001B[0m X_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([promedio_rgb])\n\u001B[1;32m---> 45\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodelo_rbf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pred[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\JupyterProject\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:374\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[0;32m    362\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    373\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 374\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    376\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, indexing_dtype(xp))\n",
      "File \u001B[1;32m~\\PycharmProjects\\JupyterProject\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    348\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    349\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 351\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    352\u001B[0m scores \u001B[38;5;241m=\u001B[39m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    354\u001B[0m     xp\u001B[38;5;241m.\u001B[39mreshape(scores, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,))\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (scores\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m scores\n\u001B[0;32m    357\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\JupyterProject\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001B[0m, in \u001B[0;36mvalidate_data\u001B[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[0m\n\u001B[0;32m   2962\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m   2964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m-> 2965\u001B[0m     \u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\PycharmProjects\\JupyterProject\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001B[0m, in \u001B[0;36m_check_n_features\u001B[1;34m(estimator, X, reset)\u001B[0m\n\u001B[0;32m   2826\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   2828\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m-> 2829\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2830\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2831\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2832\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 3 features, but LogisticRegression is expecting 8 features as input."
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
